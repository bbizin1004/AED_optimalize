# app.py
# ì²œì•ˆì‹œ AED ë°°ì¹˜ ë¶„ì„ Streamlit ëŒ€ì‹œë³´ë“œ
# - main.py ì‚°ì¶œë¬¼(csv) + SGIS Shapefile(SHP) ê²°í•©
# - ì§€ë„(folium), ë­í‚¹, ì‚°ì ë„ ì‹œê°í™”

import json
import re
from pathlib import Path

import numpy as np
import pandas as pd
import geopandas as gpd
import streamlit as st
from streamlit_folium import st_folium
import folium
import matplotlib.pyplot as plt


# í•œê¸€ í°íŠ¸ ì„¤ì • (NanumGothic)
plt.rc('font', family='NanumGothic')
plt.rc('axes', unicode_minus=False) 


# ------------------------------
# ê²½ë¡œ ì„¸íŒ…
# ------------------------------
BASE = Path(__file__).resolve().parent
DATA = BASE / "data"
OUT  = BASE / "output"

FINAL_CSV = OUT / "cheonan_eupmyeondong_aed_pop.csv"
RANK_NB_OVER  = next((OUT.glob("aed_over_alloc_top10_nb.csv")), None)
RANK_NB_UNDER = next((OUT.glob("aed_under_alloc_top10_nb.csv")), None)
RANK_P_OVER   = next((OUT.glob("aed_over_alloc_top10_poisson.csv")), None)
RANK_P_UNDER  = next((OUT.glob("aed_under_alloc_top10_poisson.csv")), None)

# ê¸°ë³¸ Shapefile íŒ¨í„´(ë™ë‚¨+ì„œë¶)
SHP_FILES = list(DATA.glob("bnd_dong_*_*.shp"))


# ìœ í‹¸
def norm(s):
    if s is None or (isinstance(s, float) and np.isnan(s)): return None
    s = str(s)
    s = re.sub(r"\s+", "", s)
    return s.replace("Â·", "")

def map_gu_name_from_sigcd(sigcd):
    m = {"44130":"ì²œì•ˆì‹œ ë™ë‚¨êµ¬", "44131":"ì²œì•ˆì‹œ ì„œë¶êµ¬"}
    return m.get(str(sigcd), None)

def pick_col(cols, bases):
    suffixes = ["", "_x", "_y"]
    for b in bases:
        for suf in suffixes:
            c = b + suf
            if c in cols:
                return c
    return None

@st.cache_data(show_spinner=False)
def load_final_csv(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path, dtype={"adm_cd":str})
    df["old_ratio"] = np.where(df["pop_total"]>0, df["pop_65p"]/df["pop_total"], np.nan)
    df["_emd_key"] = df["emd_nm"].map(norm)
    df["_gu_key"]  = df["gu"].map(norm)
    return df

@st.cache_resource(show_spinner=False)
def load_shp(files: list[Path]) -> gpd.GeoDataFrame:
    if not files:
        return gpd.GeoDataFrame()
    gdfs = []
    for shp in files:
        try:
            g = gpd.read_file(shp)
        except UnicodeDecodeError:
            g = gpd.read_file(shp, encoding="euc-kr")
        gdfs.append(g)
    gdf = pd.concat(gdfs, ignore_index=True)
    # ì¢Œí‘œê³„ ë³€í™˜ (folium: WGS84)
    try:
        if gdf.crs is None or gdf.crs.to_epsg() != 4326:
            gdf = gdf.to_crs(epsg=4326)
    except Exception:
        try:
            gdf = gdf.set_crs(epsg=5179).to_crs(epsg=4326)
        except Exception:
            pass
    return gdf

def auto_identify_cols(gdf: gpd.GeoDataFrame):
    cols = list(gdf.columns)
    emd_name_col = None
    for c in ["EMD_KOR_NM","EMD_NM","EMD_NAME","ADM_NM","adm_nm","ë²•ì •ë™","ë²•ì •ë™ëª…","í–‰ì •ë™ëª…"]:
        if c in cols:
            emd_name_col = c; break
    emd_code_col = None
    for c in ["EMD_CD","EMD_CD10","ADM_CD","adm_cd","ë²•ì •ë™ì½”ë“œ","HCODE"]:
        if c in cols:
            emd_code_col = c; break
    sig_name_col = None
    for c in ["SIG_KOR_NM","SIGUNGU_NM","SIG_KOR","SIG_NM","SIG_NAME","ì‹œêµ°êµ¬ëª…"]:
        if c in cols:
            sig_name_col = c; break
    sig_code_col = None
    for c in ["SIG_CD","sig_cd","SIGCODE","ì‹œêµ°êµ¬ì½”ë“œ"]:
        if c in cols:
            sig_code_col = c; break
    return emd_name_col, emd_code_col, sig_name_col, sig_code_col

def merge_geo(gdf: gpd.GeoDataFrame, df: pd.DataFrame) -> gpd.GeoDataFrame:
    emd_name_col, emd_code_col, sig_name_col, sig_code_col = auto_identify_cols(gdf)
    if not emd_name_col:
        raise ValueError(f"SHP ë™ëª… ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•¨. ì»¬ëŸ¼: {list(gdf.columns)}")

    # êµ¬ëª… ì—†ìœ¼ë©´ ì½”ë“œì—ì„œ ë³µì›(ADM_CD ì• 5ìë¦¬)
    if not sig_name_col:
        if not sig_code_col and emd_code_col:
            gdf["_SIG_CD_FROM_ADM"] = gdf[emd_code_col].astype(str).str[:5]
            sig_code_col = "_SIG_CD_FROM_ADM"
        if sig_code_col:
            gdf["_SIG_NAME_FROM_CD"] = gdf[sig_code_col].map(map_gu_name_from_sigcd)
            sig_name_col = "_SIG_NAME_FROM_CD"

    gdf = gdf.copy()
    gdf["_emd_nm"]  = gdf[emd_name_col].astype(str)
    gdf["_emd_key"] = gdf["_emd_nm"].map(norm)
    if sig_name_col:
        gdf["_gu_nm"]  = gdf[sig_name_col].astype(str)
        gdf["_gu_key"] = gdf["_gu_nm"].map(norm)
    else:
        gdf["_gu_nm"] = None; gdf["_gu_key"] = None

    merged = None
    if emd_code_col and "adm_cd" in df.columns:
        gdf["_emd_cd"] = gdf[emd_code_col].astype(str).str[:10]
        merged = gdf.merge(df, left_on="_emd_cd", right_on="adm_cd", how="left")
    if merged is None or merged["aed_count"].isna().all():
        merged = gdf.merge(df, left_on=["_emd_key","_gu_key"], right_on=["_emd_key","_gu_key"], how="left")
    return merged

def load_rank_csvs() -> tuple[pd.DataFrame|None, pd.DataFrame|None]:
    # NB ìš°ì„ , ì—†ìœ¼ë©´ Poisson
    over = pd.read_csv(RANK_NB_OVER) if RANK_NB_OVER and RANK_NB_OVER.exists() else \
           (pd.read_csv(RANK_P_OVER) if RANK_P_OVER and RANK_P_OVER.exists() else None)
    under = pd.read_csv(RANK_NB_UNDER) if RANK_NB_UNDER and RANK_NB_UNDER.exists() else \
            (pd.read_csv(RANK_P_UNDER) if RANK_P_UNDER and RANK_P_UNDER.exists() else None)
    return over, under


# UI
st.set_page_config(page_title="ì²œì•ˆì‹œ AED ë¶„ì„", layout="wide")
st.title("ì²œì•ˆì‹œ AED ë°°ì¹˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

with st.sidebar:
    st.header("ë°ì´í„° ì„ íƒ")
    final_csv_path = st.text_input("ê²°ê³¼ CSV ê²½ë¡œ", str(FINAL_CSV))
    shp_info = st.write("SHP ìë™ íƒìƒ‰:", ", ".join(p.name for p in SHP_FILES) or "ì—†ìŒ")
    metric = st.selectbox("ì§€ë„ ì§€í‘œ", ["aed_per_10k", "aed_per_1k_65p"], format_func=lambda x: "1ë§Œëª…ë‹¹ AED" if x=="aed_per_10k" else "65ì„¸ 1ì²œëª…ë‹¹ AED")
    quantiles = st.slider("ìƒ‰ìƒ ë¶„ìœ„ ê²½ê³„(20~80%)", 20, 80, (20,80))
    show_labels = st.checkbox("íˆ´íŒì— ì¸êµ¬/AED í‘œì‹œ", True)

# ë°ì´í„° ë¡œë“œ
try:
    df_final = load_final_csv(Path(final_csv_path))
except Exception as e:
    st.error(f"ê²°ê³¼ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

if not SHP_FILES:
    st.warning("data/ í´ë”ì— Shapefile(.shp/.shx/.dbf...)ì„ ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

gdf_raw = load_shp(SHP_FILES)
if gdf_raw.empty:
    st.error("Shapefile ë¡œë“œ ì‹¤íŒ¨")
    st.stop()

try:
    gdf = merge_geo(gdf_raw, df_final)
except Exception as e:
    st.error(f"Shapefile-ê²°ê³¼ ë³‘í•© ì‹¤íŒ¨: {e}")
    st.stop()

# KPI
c1, c2, c3, c4 = st.columns(4)
with c1:
    st.metric("í–‰ì •ë™ ìˆ˜", int(gdf.shape[0]))
with c2:
    st.metric("ì´ AED ìˆ˜(ì§‘ê³„)", int(np.nansum(df_final["aed_count"])))
with c3:
    st.metric("ì´ ì¸êµ¬", f"{int(np.nansum(df_final['pop_total'])):,}")
with c4:
    st.metric("65ì„¸ ì´ìƒ ì¸êµ¬", f"{int(np.nansum(df_final['pop_65p'])):,}")


# íƒ­
tab1, tab2, tab3 = st.tabs(["ğŸ—º ì§€ë„", "ğŸ“Š ë­í‚¹", "ğŸ”¬ ì‚°ì ë„"])

#TAB1: ì§€ë„ 
with tab1:
    st.subheader("í–‰ì •ë™ë³„ AED ë°€ë„ ì§€ë„")
    # ë¶„ìœ„ ê²½ê³„
    col_vals = pd.to_numeric(gdf[metric], errors="coerce")
    if col_vals.notna().any():
        q_low  = col_vals.quantile(quantiles[0]/100)
        q_mid1 = col_vals.quantile(0.4)
        q_mid2 = col_vals.quantile(0.6)
        q_high = col_vals.quantile(quantiles[1]/100)
        qs = [q_low, q_mid1, q_mid2, q_high]
    else:
        qs = None

    m = folium.Map(location=[36.815, 127.146], zoom_start=11, tiles="cartodbpositron")
    gjson = json.loads(gdf.to_json())

    def style_fn(feat):
        p = feat["properties"]
        val = p.get(metric, None)
        fill_opacity = 0.7 if val is not None else 0.0
        color = "#f7fbff"
        if val is not None and qs is not None:
            if val <= qs[0]: color = "#deebf7"
            elif val <= qs[1]: color = "#c6dbef"
            elif val <= qs[2]: color = "#9ecae1"
            elif val <= qs[3]: color = "#6baed6"
            else: color = "#3182bd"
        return {"fillColor": color, "color": "#555555", "weight": 0.6, "fillOpacity": fill_opacity}

    tooltip_fields = ["_gu_nm", "_emd_nm"]
    tooltip_alias  = ["êµ¬", "ìë©´ë™"]
    if show_labels:
        for c in ["aed_count","pop_total","pop_65p", metric]:
            if c in gdf.columns:
                tooltip_fields.append(c)
                tooltip_alias.append({"aed_count":"AED ìˆ˜","pop_total":"ì´ì¸êµ¬","pop_65p":"65ì„¸+","aed_per_10k":"1ë§Œëª…ë‹¹ AED","aed_per_1k_65p":"65ì„¸ 1ì²œëª…ë‹¹ AED"}\
                                      .get(c, c))

    folium.GeoJson(
        gjson,
        name="AED Choropleth",
        style_function=style_fn,
        tooltip=folium.features.GeoJsonTooltip(fields=tooltip_fields, aliases=tooltip_alias, sticky=True)
    ).add_to(m)

    st_folium(m, height=620, use_container_width=True)

#TAB2: ë­í‚¹
with tab2:
    st.subheader("ì˜ˆìƒ ëŒ€ë¹„ ê³¼ë‹¤/ê³¼ì†Œ ë°°ì¹˜ TOP10 (í‘œì¤€í™” ì”ì°¨)")
    over_df, under_df = load_rank_csvs()
    if (over_df is None) or (under_df is None):
        st.info("ë­í‚¹ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. main.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
    else:
        # ì»¬ëŸ¼ ìë™ ì„ íƒ
        label_col = pick_col(over_df.columns, ["emd_nm","ADM_NM","ìë©´ë™","ìë©´ë™ëª…","í–‰ì •ë™ëª…","ë²•ì •ë™ëª…"]) or "emd_nm"
        gu_col    = pick_col(over_df.columns, ["gu","êµ¬","sigungu","SIG_KOR_NM"])
        val_col   = pick_col(over_df.columns, ["std_resid"]) or "std_resid"

        col1, col2 = st.columns(2)
        for title, df_rank, container in [
            ("ê³¼ë‹¤ ë°°ì¹˜ TOP 10", over_df, col1),
            ("ê³¼ì†Œ ë°°ì¹˜ TOP 10", under_df, col2)
        ]:
            with container:
                tdf = df_rank.copy()
                if len(tdf) > 10: tdf = tdf.head(10)
                # ë¼ë²¨
                if gu_col and gu_col in tdf.columns:
                    tdf["_label"] = (tdf[gu_col].astype(str).fillna("") + " " + tdf[label_col].astype(str).fillna("")).str.strip()
                else:
                    tdf["_label"] = tdf[label_col].astype(str)

                st.dataframe(tdf[[label_col, gu_col, val_col]].rename(columns={
                    label_col:"ìë©´ë™", gu_col:"êµ¬", val_col:"í‘œì¤€í™”ì”ì°¨"
                }), use_container_width=True, hide_index=True)

                # ë§‰ëŒ€ ê·¸ë˜í”„ (matplotlib, ìƒ‰ ë¯¸ì§€ì •, í•œ ê·¸ë¦¼ í•œ ì°¨íŠ¸)
                plt.figure(figsize=(6, 4))
                y = np.arange(len(tdf))
                plt.barh(y, tdf[val_col].values)
                plt.yticks(y, tdf["_label"].values)
                plt.title(title)
                plt.xlabel("í‘œì¤€í™” ì”ì°¨")
                plt.tight_layout()
                st.pyplot(plt.gcf())
                plt.close()

#TAB3: ì‚°ì ë„
with tab3:
    st.subheader("ê´€ê³„ íƒìƒ‰")
    c1, c2 = st.columns(2)

    with c1:
        st.caption("ì´ì¸êµ¬ vs AED ìˆ˜ (ì  í¬ê¸°=ê³ ë ¹ë¹„)")
        plt.figure(figsize=(6, 4.5))
        sizes = (df_final["old_ratio"].fillna(0.0) * 800) + 20
        plt.scatter(df_final["pop_total"], df_final["aed_count"], s=sizes)  # ìƒ‰ ì§€ì • X
        plt.xlabel("ì´ì¸êµ¬")
        plt.ylabel("AED ìˆ˜")
        plt.tight_layout()
        st.pyplot(plt.gcf())
        plt.close()

    with c2:
        st.caption("ê³ ë ¹ë¹„ vs 1ë§Œëª…ë‹¹ AED")
        plt.figure(figsize=(6, 4.5))
        plt.scatter(df_final["old_ratio"], df_final["aed_per_10k"])         # ìƒ‰ ì§€ì • X
        plt.xlabel("ê³ ë ¹ë¹„ (65+/ì´ì¸êµ¬)")
        plt.ylabel("1ë§Œëª…ë‹¹ AED")
        plt.tight_layout()
        st.pyplot(plt.gcf())
        plt.close()

st.success("ëŒ€ì‹œë³´ë“œ ì¤€ë¹„ ì™„ë£Œ!")
